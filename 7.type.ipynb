{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd26985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_celsius           float64\n",
      "age_years                       int64\n",
      "timestamp_event        datetime64[ns]\n",
      "product_category               object\n",
      "is_purchased                     bool\n",
      "humidity_percentage           float64\n",
      "income_usd                      int64\n",
      "last_updated           datetime64[ns]\n",
      "product_name                   object\n",
      "is_subscribed                    bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "\n",
    "# создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df_int = df.select_dtypes(include='int')\n",
    "df_float = df.select_dtypes(include='float')\n",
    "df_bool = df.select_dtypes(include='bool')\n",
    "df_object = df.select_dtypes(include='object')\n",
    "df_date = df.select_dtypes(include='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622cdf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "[ 2.,  0.,  0.],\n",
    "[ 0.,  1., -1.]])\n",
    "\n",
    "transformer = StandardScaler().fit(X_train) # оцениваем параметры модели\n",
    "transformer.mean_ # получаем средние значения для преобразования\n",
    "transformer.scale_ # получаем масштабы для преобразования\n",
    "\n",
    "X_scaled = transformer.transform(X_train) # применяем преобразование к данным\n",
    "X_scaled # получаем преобразованные данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4485665",
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.preprocessing import OneHotEncoder\n",
    "  import numpy as np\n",
    "  \n",
    "  data = np.array(['Универсал', 'Седан', 'Универсал', 'Хэтчбек']).reshape(-1, 1)\n",
    "  encoder = OneHotEncoder()\n",
    "  encoded_data = encoder.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72528f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.preprocessing import SplineTransformer\n",
    "    import numpy as np\n",
    "    \n",
    "    X = np.random.rand(10, 1)\n",
    "    transformer = SplineTransformer(n_knots=3, degree=2)\n",
    "    X_transformed = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967c918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2663: UserWarning: n_quantiles (1000) is greater than the total number of samples (10). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  from sklearn.preprocessing import QuantileTransformer\n",
    "  import numpy as np\n",
    "  \n",
    "  X = np.random.rand(10, 1)\n",
    "  transformer = QuantileTransformer()\n",
    "  X_transformed = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756e7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  from sklearn.preprocessing import KBinsDiscretizer\n",
    "  import numpy as np\n",
    "  \n",
    "  X = np.array([[2.3], [5.6], [7.8], [1.2]])\n",
    "  est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "  est.fit(X)\n",
    "  transformed = est.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe10b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler, LabelEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "\n",
    "# создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "thr = df['income_usd'].mean()\n",
    "binzr = Binarizer(threshold=thr)\n",
    "df['income_usd_binarized'] = binzr.fit_transform(df[['income_usd']]).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['age_years_standarded'] = scaler.fit_transform(df[['age_years']])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['is_subscribed_encoded'] = le.fit_transform(df['is_subscribed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d7f675",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[1;32m      3\u001b[0m all_transformers \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m      4\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m----> 5\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНазвание энкодера #1\u001b[39m\u001b[38;5;124m\"\u001b[39m, QuantileTransformer(), \u001b[43mcolumns\u001b[49m), \u001b[38;5;66;03m# преобразование 1 и соответствующие колонки\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНазвание энкодера #2\u001b[39m\u001b[38;5;124m\"\u001b[39m, SplineTransformer(), columns), \u001b[38;5;66;03m# Преобразование 2 и соответствующие колонки\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ]\n\u001b[1;32m      8\u001b[0m ) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "all_transformers = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"Название энкодера #1\", QuantileTransformer(), columns), # преобразование 1 и соответствующие колонки\n",
    "        (\"Название энкодера #2\", SplineTransformer(), columns), # Преобразование 2 и соответствующие колонки\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86deb305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# генерация случайных данных\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# определение числовых признаков для ColumnTransformer\n",
    "numeric_features = [0, 1, 2, 3]  # пример числовых признаков (нумерация с 0)\n",
    "\n",
    "# создание ColumnTransformer с преобразованиями для числовых признаков\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)  # преобразования для числовых признаков\n",
    "    ])\n",
    "\n",
    "# создание Pipeline с преобразованиями и моделью\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', SVC())])\n",
    "\n",
    "# обучение модели\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# оценка качества модели на тестовых данных\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be080a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "thr = df['income_usd'].mean()\n",
    "# создание ColumnTransformer с преобразованиями для различных колонок\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bin_income', Binarizer(threshold=thr), ['income_usd']),      # Binarizer\n",
    "        ('scale_age', StandardScaler(), ['age_years']),                # StandardScaler\n",
    "        ('ohe_sub', OneHotEncoder(sparse=False), ['is_subscribed'])    # OneHotEncoder\n",
    "    ],\n",
    "    remainder='drop'   # или 'passthrough', если нужно сохранить остальные колонки\n",
    ")\n",
    "\n",
    "# создание Pipeline с преобразованиями\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor)\n",
    "])\n",
    "\n",
    "transformed_data = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba2b4f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Random_Dates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Random_Dates'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Извлечение признаков из даты\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRandom_Dates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom_Dates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom_Dates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Random_Dates'"
     ]
    }
   ],
   "source": [
    "# 1. Извлечение признаков из даты\n",
    "df['Year'] = df['Random_Dates'].dt.year\n",
    "df['Month'] = df['Random_Dates'].dt.month\n",
    "df['Day'] = df['Random_Dates'].dt.day\n",
    "df['Weekday'] = df['Random_Dates'].dt.weekday\n",
    "df['Hour'] = df['Random_Dates'].dt.hour\n",
    "\n",
    "# 2. Расчёт временных интервалов (разница между двумя датами)\n",
    "df['Date_2'] = pd.to_datetime(np.random.randint(start_date.value, end_date.value, n_samples))\n",
    "df['Date_Difference'] = (df['Date_2'] - df['Random_Dates']).dt.days\n",
    "\n",
    "# 3. Скользящие окна и накопительные статистики\n",
    "rolling_mean = df['Date_Difference'].rolling(window=7).mean()\n",
    "cumulative_sum = df['Date_Difference'].cumsum()\n",
    "\n",
    "# 4. Периодичность и тренды\n",
    "df['Trend'] = df['Random_Dates'].dt.month * np.random.rand(n_samples)  # пример генерации тренда\n",
    "df['Season'] = df['Random_Dates'].dt.month % 4  # деление на 4 для сезонов (в качестве примера)\n",
    "\n",
    "# 5. Преобразование времени в категориальные признаки с помощью OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "month_encoded = one_hot_encoder.fit_transform(df[['Month']])\n",
    "columns = [f\"Month_{month}\" for month in one_hot_encoder.categories_[0][1:]]\n",
    "month_encoded_df = pd.DataFrame(month_encoded, columns=columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d262200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Temperature_Celsius  Month  Weekday  Hour  RollingMean_7   \n",
      "0 2023-01-01             4.981605      1        6     0       4.981605  \\\n",
      "1 2023-01-02            28.028572      1        0     0      16.505089   \n",
      "2 2023-01-03            19.279758      1        1     0      17.429978   \n",
      "3 2023-01-04            13.946339      1        2     0      16.559069   \n",
      "4 2023-01-05            -3.759254      1        3     0      12.495404   \n",
      "\n",
      "   Cumulative_Sum  Monthly_Sum  Monthly_Mean  \n",
      "0        4.981605   240.618521      7.761888  \n",
      "1       33.010177   240.618521      7.761888  \n",
      "2       52.289935   240.618521      7.761888  \n",
      "3       66.236274   240.618521      7.761888  \n",
      "4       62.477020   240.618521      7.761888  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# генерация случайных данных о температурах за год\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "start_date = pd.Timestamp('2023-01-01')\n",
    "end_date = pd.Timestamp('2023-12-31')\n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "temperatures = np.random.uniform(low=-10.0, high=30.0, size=len(dates))\n",
    "temperature_data = pd.DataFrame({'Date': dates, 'Temperature_Celsius': temperatures})\n",
    "\n",
    "# 1. Извлечение признаков из даты\n",
    "temperature_data['Month'] = temperature_data['Date'].dt.month\n",
    "temperature_data['Weekday'] = temperature_data['Date'].dt.weekday      \n",
    "temperature_data['Hour'] = temperature_data['Date'].dt.hour \n",
    "\n",
    "# 2. Скользящие окна и накопительные статистики\n",
    "temperature_data = temperature_data.sort_values('Date')\n",
    "temperature_data['RollingMean_7'] = (\n",
    "    temperature_data['Temperature_Celsius'].rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "temperature_data['Cumulative_Sum'] = temperature_data['Temperature_Celsius'].cumsum()\n",
    "\n",
    "# 3. Периодичность и тренды (по месяцам)\n",
    "temperature_data['Monthly_Sum'] = (\n",
    "    temperature_data.groupby(pd.Grouper(key='Date', freq='M'))['Temperature_Celsius']\n",
    "    .transform('sum')\n",
    ")\n",
    "temperature_data['Monthly_Mean'] = (\n",
    "    temperature_data.groupby(pd.Grouper(key='Date', freq='M'))['Temperature_Celsius']\n",
    "    .transform('mean')\n",
    ")\n",
    "\n",
    "# вывод обработанных данных\n",
    "print(temperature_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# генерация случайных данных о температурах за год\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "start_date = pd.Timestamp('2023-01-01')\n",
    "end_date = pd.Timestamp('2023-12-31')\n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "temperatures = np.random.uniform(low=-10.0, high=30.0, size=len(dates))\n",
    "temperature_data = pd.DataFrame({'Date': dates, 'Temperature_Celsius': temperatures})\n",
    "\n",
    "# ваш код для предобработки временных признаков #\n",
    "# 1. Извлечение признаков из даты\n",
    "temperature_data['Month'] = temperature_data['Date'].dt.month\n",
    "temperature_data['Weekday'] = temperature_data['Date'].dt.weekday      \n",
    "temperature_data['Hour'] = temperature_data['Date'].dt.hour \n",
    "\n",
    "# 2. Скользящие окна и накопительные статистики\n",
    "temperature_data['Cumulative_Sum'] = temperature_data['Temperature_Celsius'].cumsum()\n",
    "\n",
    "# 3. Периодичность и тренды\n",
    "temperature_data['Monthly_Sum'] = temperature_data.groupby('Month')['Temperature_Celsius'].transform('sum') \n",
    "temperature_data['Monthly_Mean'] = temperature_data.groupby('Month')['Temperature_Celsius'].transform('mean')\n",
    "\n",
    "# вывод обработанных данных\n",
    "print(temperature_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
